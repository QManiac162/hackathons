{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRSGgoPmhhMH",
        "outputId": "f28ecc89-eb66-407b-968b-cc9279fab019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Collecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-cpu)\n",
            "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.66.1)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow-cpu)\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.2.0 (from tensorflow-cpu)\n",
            "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow-cpu) (13.8.1)\n",
            "Collecting namex (from keras>=3.2.0->tensorflow-cpu)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.2.0->tensorflow-cpu)\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m749.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow-cpu) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow-cpu) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-cpu) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-cpu) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (221.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, tensorboard, keras, tensorflow-cpu\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "Successfully installed keras-3.5.0 ml-dtypes-0.4.1 namex-0.0.8 optree-0.12.1 tensorboard-2.17.1 tensorflow-cpu-2.17.0\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.0+cpu)\n",
            "Collecting opencv-python-headless (from easyocr)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (10.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Collecting Shapely (from easyocr)\n",
            "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.9.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, Shapely, opencv-python-headless, easyocr\n",
            "Successfully installed Shapely-2.0.6 easyocr-1.7.1 ninja-1.11.1.1 opencv-python-headless-4.10.0.84 pyclipper-1.3.0.post5 python-bidi-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-cpu\n",
        "!pip install easyocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS_E0iAVkOW7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import re\n",
        "import easyocr\n",
        "reader = easyocr.Reader(['en'])\n",
        "# reader = easyocr.Reader([\"en\"],gpu=True,quantize=True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5fi3sy-kids",
        "outputId": "816dd8ce-0684-43e4-cca1-6f7b15603524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1Pc0xZA6kpt6"
      },
      "outputs": [],
      "source": [
        "# Abbreviation map\n",
        "unit_abbreviation_map = {\n",
        "    'cm': 'centimetre', 'mm': 'millimetre', 'm': 'metre', 'in': 'inch', 'ft': 'foot', 'yd': 'yard',\n",
        "    'g': 'gram', 'kg': 'kilogram', 'mg': 'milligram', 'oz': 'ounce', 'lb': 'pound', 't': 'ton',\n",
        "    'kV': 'kilovolt', 'V': 'volt', 'mV': 'millivolt',\n",
        "    'kW': 'kilowatt', 'W': 'watt',\n",
        "    'cl': 'centilitre', 'ml': 'millilitre', 'l': 'litre', 'fl oz': 'fluid ounce', 'gal': 'gallon',\n",
        "    'pt': 'pint', 'qt': 'quart', 'cu ft': 'cubic foot', 'cu in': 'cubic inch'\n",
        "}\n",
        "\n",
        "# Entity-unit map\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce',\n",
        "                    'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0BkPknF7ksL-"
      },
      "outputs": [],
      "source": [
        "# Function to get all relevant units and abbreviations for an entity\n",
        "def get_entity_units(entity_name):\n",
        "    if entity_name not in entity_unit_map:\n",
        "        return set()\n",
        "\n",
        "    units = entity_unit_map[entity_name]\n",
        "    # Find abbreviations that map to these units\n",
        "    abbreviations = {abbr for abbr, full in unit_abbreviation_map.items() if full in units}\n",
        "    # Combine full units and their abbreviations\n",
        "    return units.union(abbreviations)\n",
        "\n",
        "# Function to extract entity values with abbreviation handling\n",
        "def extract_entity_values(text, entity_name):\n",
        "    valid_units = get_entity_units(entity_name)\n",
        "    if not valid_units:\n",
        "        return []\n",
        "\n",
        "    # Build regex pattern to match numbers followed by valid units or their abbreviations\n",
        "    # Sort by length to handle multi-word units like 'fluid ounce'\n",
        "    sorted_units = sorted(valid_units, key=lambda x: -len(x))\n",
        "    pattern = r'(\\d+(?:\\.\\d+)?)\\s*(' + '|'.join(map(re.escape, sorted_units)) + r')\\b'\n",
        "\n",
        "    # Find all matches\n",
        "    matches = re.findall(pattern, text)\n",
        "\n",
        "    extracted = []\n",
        "    for value, unit in matches:\n",
        "        # Convert abbreviation to full unit name if necessary\n",
        "        full_unit = unit_abbreviation_map.get(unit, unit)\n",
        "        extracted.append((float(value), full_unit))\n",
        "\n",
        "    return extracted\n",
        "\n",
        "# Function to select the appropriate value based on entity rules\n",
        "def select_entity_value(extracted_values, entity_name):\n",
        "    if not extracted_values:\n",
        "        return \"\"\n",
        "\n",
        "    # Extract numerical values\n",
        "    values = [val for val, unit in extracted_values]\n",
        "\n",
        "    if entity_name == 'height':\n",
        "        selected = max(values)\n",
        "    elif entity_name == 'width':\n",
        "        if len(values) >= 2:\n",
        "            sorted_vals = sorted(values, reverse=True)\n",
        "            selected = sorted_vals[1]  # Second maximum\n",
        "        else:\n",
        "            selected = max(values)\n",
        "    elif entity_name == 'depth':\n",
        "        selected = min(values)\n",
        "    elif entity_name == 'maximum_weight_recommendation':\n",
        "        selected = max(values)\n",
        "    else:\n",
        "        selected = values[0]  # Default to first value\n",
        "\n",
        "    # Find the corresponding unit\n",
        "    for val, unit in extracted_values:\n",
        "        if val == selected:\n",
        "            return f\"{val} {unit}\"\n",
        "\n",
        "    return \"\"  # Fallback in case something goes wrong\n",
        "\n",
        "# Function to process all texts for a specific entity\n",
        "def process_texts(texts, entity_name):\n",
        "    all_extracted = []\n",
        "    for text in texts:\n",
        "        extracted = extract_entity_values(text, entity_name)\n",
        "        all_extracted.extend(extracted)\n",
        "\n",
        "    selected_value = select_entity_value(all_extracted, entity_name)\n",
        "    return selected_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k0FSsrE_kuZp"
      },
      "outputs": [],
      "source": [
        "# Predictor function integrating OCR and entity extraction\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "def predictor(image_link, category_id, entity_name):\n",
        "\n",
        "    # Extract image name from the link\n",
        "    image_name = os.path.basename(image_link)\n",
        "\n",
        "    try:\n",
        "        # Load the image\n",
        "        response = requests.get(image_link)\n",
        "\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        # Run OCR\n",
        "        results = reader.readtext(image, detail=0)\n",
        "        # Extract texts from OCR predictions\n",
        "        extracted_texts = results\n",
        "        prediction = process_texts(extracted_texts, entity_name)\n",
        "        return prediction\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Image {image_name} not found in the folder.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbWcCLdFkwkf",
        "outputId": "6f831c21-7b4a-4ee9-d16e-357677c79e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted index:  81764\n",
            "predicted index:  81765\n",
            "predicted index:  81766\n",
            "predicted index:  81767\n",
            "predicted index:  81768\n",
            "predicted index:  81769\n",
            "predicted index:  81770\n",
            "predicted index:  81771\n",
            "predicted index:  81772\n",
            "predicted index:  81773\n",
            "predicted index:  81774\n",
            "predicted index:  81775\n",
            "predicted index:  81776\n",
            "predicted index:  81777\n",
            "predicted index:  81778\n",
            "predicted index:  81779\n",
            "predicted index:  81780\n",
            "predicted index:  81781\n",
            "predicted index:  81782\n",
            "predicted index:  81783\n",
            "predicted index:  81784\n",
            "predicted index:  81785\n",
            "predicted index:  81786\n",
            "predicted index:  81787\n",
            "predicted index:  81788\n",
            "predicted index:  81789\n",
            "predicted index:  81790\n",
            "predicted index:  81791\n",
            "predicted index:  81792\n",
            "predicted index:  81793\n",
            "predicted index:  81794\n",
            "predicted index:  81795\n",
            "predicted index:  81796\n",
            "predicted index:  81797\n",
            "predicted index:  81798\n",
            "predicted index:  81799\n",
            "predicted index:  81800\n",
            "predicted index:  81801\n",
            "predicted index:  81802\n",
            "predicted index:  81803\n",
            "predicted index:  81804\n",
            "predicted index:  81805\n",
            "predicted index:  81806\n",
            "predicted index:  81807\n",
            "predicted index:  81808\n",
            "predicted index:  81809\n",
            "predicted index:  81810\n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Load test CSV\n",
        "    output_filename = '/content/drive/MyDrive/template-new/dataset/t81764-85000.csv'\n",
        "    test = pd.read_csv('/content/drive/MyDrive/template-new/dataset/test.csv')\n",
        "    test_subset = test.iloc[81764:850000]\n",
        "\n",
        "# Write headers to the CSV file (to create the file)\n",
        "    with open(output_filename, mode='w') as f:\n",
        "        f.write(\"index,prediction\\n\")\n",
        "\n",
        "# Run predictions and append each result to the CSV file\n",
        "    for index, row in test_subset.iterrows():\n",
        "        prediction = predictor(row['image_link'], row['group_id'], row['entity_name'])\n",
        "        print(\"predicted index: \", index)\n",
        "        with open(output_filename, mode='a') as f:\n",
        "          f.write(f\"{row['index']},{prediction}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}